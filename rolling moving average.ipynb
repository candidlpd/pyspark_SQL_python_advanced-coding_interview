{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\pyspark_advanced-coding_interview\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"H:\\pyspark_advanced-coding_interview\")\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session with optimized settings\n",
    "spark = (\n",
    "    SparkSession.builder \n",
    "    .appName(\"OptimizedLocalSpark\") \n",
    "    .config(\"spark.driver.memory\", \"8g\")        \n",
    "    .config(\"spark.executor.memory\", \"8g\")    \n",
    "    .config(\"spark.executor.cores\", \"4\")       \n",
    "    .config(\"spark.cores.max\", \"12\")           \n",
    "    .config(\"spark.sql.shuffle.partitions\", \"28\")  \n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to calculate rolling / moving average ? | Ex - 3 day rolling average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----+\n",
      "| id|      date|value|\n",
      "+---+----------+-----+\n",
      "|  1|2024-10-01|  100|\n",
      "|  2|2024-10-02|  200|\n",
      "|  3|2024-10-03|  300|\n",
      "|  4|2024-10-04|  400|\n",
      "|  5|2024-10-05|  500|\n",
      "|  6|2024-10-06|  600|\n",
      "+---+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"RollingAverageExample\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (1, '2024-10-01', 100),\n",
    "    (2, '2024-10-02', 200),\n",
    "    (3, '2024-10-03', 300),\n",
    "    (4, '2024-10-04', 400),\n",
    "    (5, '2024-10-05', 500),\n",
    "    (6, '2024-10-06', 600)\n",
    "]\n",
    "\n",
    "columns = [\"id\", \"date\", \"value\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Create a temporary table\n",
    "df.createOrReplaceTempView(\"temp_table\")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----+----------------+\n",
      "| id|      date|value|rolling_avg_3day|\n",
      "+---+----------+-----+----------------+\n",
      "|  1|2024-10-01|  100|           100.0|\n",
      "|  2|2024-10-02|  200|           150.0|\n",
      "|  3|2024-10-03|  300|           200.0|\n",
      "|  4|2024-10-04|  400|           300.0|\n",
      "|  5|2024-10-05|  500|           400.0|\n",
      "|  6|2024-10-06|  600|           500.0|\n",
      "+---+----------+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = spark.sql(\"\"\"  \n",
    "    SELECT \n",
    "    id,\n",
    "    date,\n",
    "    value,\n",
    "    AVG(value) OVER (ORDER BY date  ROWS BETWEEN 2 PRECEDING AND CURRENT ROW\n",
    "    ) AS rolling_avg_3day\n",
    "FROM temp_table\n",
    "ORDER BY date\n",
    "            \n",
    "                \"\"\")\n",
    "\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----+------------------+\n",
      "| id|      date|value|  rolling_avg_3day|\n",
      "+---+----------+-----+------------------+\n",
      "|  1|2024-10-01|  100|33.333333333333336|\n",
      "|  2|2024-10-02|  200|             100.0|\n",
      "|  3|2024-10-03|  300|             200.0|\n",
      "|  4|2024-10-04|  400|             300.0|\n",
      "|  5|2024-10-05|  500|             400.0|\n",
      "|  6|2024-10-06|  600|             500.0|\n",
      "+---+----------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_sql_alternative = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        id,\n",
    "        date,\n",
    "        value,\n",
    "        (value + COALESCE(LAG(value, 1) OVER (ORDER BY date), 0) + COALESCE(LAG(value, 2) OVER (ORDER BY date), 0)) / 3 AS rolling_avg_3day\n",
    "    FROM temp_table\n",
    "    ORDER BY date\n",
    "\"\"\")\n",
    "\n",
    "result_sql_alternative.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-----+----------------+\n",
      "| id|      date|value|rolling_avg_3day|\n",
      "+---+----------+-----+----------------+\n",
      "|  1|2024-10-01|  100|           100.0|\n",
      "|  2|2024-10-02|  200|           150.0|\n",
      "|  3|2024-10-03|  300|           200.0|\n",
      "|  4|2024-10-04|  400|           300.0|\n",
      "|  5|2024-10-05|  500|           400.0|\n",
      "|  6|2024-10-06|  600|           500.0|\n",
      "+---+----------+-----+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Define the window\n",
    "window_spec = Window.orderBy(\"date\").rowsBetween(-2, 0)\n",
    "\n",
    "# Calculate rolling average\n",
    "df_with_rolling_avg = df.withColumn(\"rolling_avg_3day\", F.avg(\"value\").over(window_spec))\n",
    "df_with_rolling_avg.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
