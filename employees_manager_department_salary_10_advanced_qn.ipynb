{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\pyspark_advanced-coding_interview\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"H:\\pyspark_advanced-coding_interview\")\n",
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session with optimized settings\n",
    "spark = (\n",
    "    SparkSession.builder \n",
    "    .appName(\"OptimizedLocalSpark\") \n",
    "    .config(\"spark.driver.memory\", \"8g\")        \n",
    "    .config(\"spark.executor.memory\", \"8g\")    \n",
    "    .config(\"spark.executor.cores\", \"4\")       \n",
    "    .config(\"spark.cores.max\", \"12\")           \n",
    "    .config(\"spark.sql.shuffle.partitions\", \"28\")  \n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-----------+------+----------+\n",
      "|employee_id|   name| department|salary|manager_id|\n",
      "+-----------+-------+-----------+------+----------+\n",
      "|          1|  Alice|Engineering| 80000|      null|\n",
      "|          2|    Bob|Engineering| 70000|         1|\n",
      "|          3|Charlie|Engineering| 60000|         1|\n",
      "|          4|  David|  Marketing| 90000|      null|\n",
      "|          5|    Eve|  Marketing| 55000|         4|\n",
      "|          6|  Frank|  Marketing| 65000|         4|\n",
      "|          7|  Grace|      Sales| 75000|      null|\n",
      "|          8| Hannah|      Sales| 70000|         7|\n",
      "|          9|    Ian|      Sales| 65000|         7|\n",
      "+-----------+-------+-----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"EmployeeQueries\").getOrCreate()\n",
    "\n",
    "# Sample data for employees\n",
    "data = [\n",
    "    (1, 'Alice', 'Engineering', 80000, None),     # Manager of Engineering\n",
    "    (2, 'Bob', 'Engineering', 70000, 1),\n",
    "    (3, 'Charlie', 'Engineering', 60000, 1),\n",
    "    (4, 'David', 'Marketing', 90000, None),       # Manager of Marketing\n",
    "    (5, 'Eve', 'Marketing', 55000, 4),\n",
    "    (6, 'Frank', 'Marketing', 65000, 4),\n",
    "    (7, 'Grace', 'Sales', 75000, None),           # Manager of Sales\n",
    "    (8, 'Hannah', 'Sales', 70000, 7),\n",
    "    (9, 'Ian', 'Sales', 65000, 7)\n",
    "]\n",
    "\n",
    "columns = [\"employee_id\", \"name\", \"department\", \"salary\", \"manager_id\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Create temporary table for SQL queries\n",
    "df.createOrReplaceTempView(\"employee_table\")\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employees with highest salary in a department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------+\n",
      "|Employee_id|salary|dense_rnk|\n",
      "+-----------+------+---------+\n",
      "|          1| 80000|        1|\n",
      "|          4| 90000|        1|\n",
      "|          7| 75000|        1|\n",
      "+-----------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = spark.sql(\"\"\" \n",
    "select Employee_id, salary, dense_rnk \n",
    "from (\n",
    "select *,\n",
    "dense_rank() over ( partition by department order by salary desc)  as dense_rnk  \n",
    "from  employee_table         \n",
    ") A\n",
    "where dense_rnk = 1 ;             \n",
    "                \"\"\")\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+\n",
      "| department|dept_max_salary|\n",
      "+-----------+---------------+\n",
      "|      Sales|          75000|\n",
      "|Engineering|          80000|\n",
      "|  Marketing|          90000|\n",
      "+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res1 = spark.sql(\"\"\" \n",
    "select department, max(salary) as dept_max_salary  from employee_table \n",
    "group by department \n",
    "order by max(salary)\n",
    "          \n",
    "                \"\"\")\n",
    "res1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+------+\n",
      "| department| name|salary|\n",
      "+-----------+-----+------+\n",
      "|      Sales|Grace| 75000|\n",
      "|Engineering|Alice| 80000|\n",
      "|  Marketing|David| 90000|\n",
      "+-----------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res2 = spark.sql(\"\"\" \n",
    "select department, name, salary \n",
    "from employee_table e\n",
    "where salary = ( Select max(salary) from employee_table where department = e.department)\n",
    "order by salary\n",
    "\n",
    "          \n",
    "                \"\"\")\n",
    "res2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employees with Salary lesser than department average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+\n",
      "| department|   name|salary|\n",
      "+-----------+-------+------+\n",
      "|  Marketing|    Eve| 55000|\n",
      "|Engineering|Charlie| 60000|\n",
      "|  Marketing|  Frank| 65000|\n",
      "|      Sales|    Ian| 65000|\n",
      "+-----------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res3= spark.sql(\"\"\" \n",
    "select department, name, salary \n",
    "from employee_table e\n",
    "where salary < ( Select avg(salary) from employee_table where department = e.department)\n",
    "order by salary\n",
    "\n",
    "          \n",
    "                \"\"\")\n",
    "res3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+--------------+\n",
      "| department|   name|salary|dpt_avg_salary|\n",
      "+-----------+-------+------+--------------+\n",
      "|Engineering|Charlie| 60000|       70000.0|\n",
      "|  Marketing|    Eve| 55000|       70000.0|\n",
      "|  Marketing|  Frank| 65000|       70000.0|\n",
      "|      Sales|    Ian| 65000|       70000.0|\n",
      "+-----------+-------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res4= spark.sql(\"\"\" \n",
    " with dpt_avg as(              \n",
    "select department, avg(salary) as dpt_avg_salary\n",
    "from employee_table\n",
    "group by department \n",
    ")\n",
    "\n",
    "\n",
    "select e.department, e.name, e.salary, d.dpt_avg_salary\n",
    "from employee_table e\n",
    "inner join dpt_avg d\n",
    "on e.department = d.department \n",
    "where e.salary < d.dpt_avg_salary\n",
    "\n",
    "\n",
    "          \n",
    "                \"\"\")\n",
    "res4.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+\n",
      "| department|   name|salary|\n",
      "+-----------+-------+------+\n",
      "|Engineering|Charlie| 60000|\n",
      "|  Marketing|    Eve| 55000|\n",
      "|  Marketing|  Frank| 65000|\n",
      "|      Sales|    Ian| 65000|\n",
      "+-----------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res5= spark.sql(\"\"\" \n",
    "SELECT e.department, e.name, e.salary\n",
    "FROM employee_table e\n",
    "JOIN (\n",
    "    SELECT department, AVG(salary) AS avg_salary\n",
    "    FROM employee_table\n",
    "    GROUP BY department\n",
    ") dept_avg\n",
    "ON e.department = dept_avg.department\n",
    "WHERE e.salary < dept_avg.avg_salary\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "                \"\"\")\n",
    "res5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employees with Salary Less Than Department Average but More Than Average of Any Other Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+----------+\n",
      "|name|salary|department|\n",
      "+----+------+----------+\n",
      "+----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res7= spark.sql(\"\"\" \n",
    "SELECT e.name, e.salary, e.department\n",
    "FROM employee_table e\n",
    "JOIN (\n",
    "    SELECT department, AVG(salary) AS avg_salary\n",
    "    FROM employee_table\n",
    "    GROUP BY department\n",
    ") dept_avg\n",
    "ON e.department = dept_avg.department\n",
    "WHERE e.salary < dept_avg.avg_salary\n",
    "AND e.salary > (\n",
    "    SELECT MAX(avg_salary)\n",
    "    FROM (\n",
    "        SELECT AVG(salary) AS avg_salary\n",
    "        FROM employee_table\n",
    "        GROUP BY department\n",
    "    ) other_depts\n",
    ")\n",
    "\n",
    "\n",
    "          \n",
    "                \"\"\")\n",
    "res7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res10= spark.sql(\"\"\" \n",
    "SELECT e.department, e.name, e.salary\n",
    "FROM employee_table e\n",
    "Inner JOIN (\n",
    "    SELECT department, AVG(salary) AS avg_salary\n",
    "    FROM employee_table\n",
    "    GROUP BY department\n",
    ") dept_avg\n",
    "ON e.department = dept_avg.department\n",
    "WHERE e.salary < dept_avg.avg_salary\n",
    "and e.salary > any(select avg(salary from employee_table groupp by department))\n",
    "\n",
    "\n",
    "\n",
    "          \n",
    "                \"\"\")\n",
    "res10.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employees with the Same Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------------+\n",
      "|employee_id|employee1|employee1_salary|\n",
      "+-----------+---------+----------------+\n",
      "|          6|    Frank|           65000|\n",
      "|          9|      Ian|           65000|\n",
      "|          2|      Bob|           70000|\n",
      "|          8|   Hannah|           70000|\n",
      "+-----------+---------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res8= spark.sql(\"\"\" \n",
    "select e1.employee_id, e1.name as employee1, e1.salary as employee1_salary\n",
    "FROM employee_table e1\n",
    "inner join employee_table e2\n",
    "on e1.salary = e2.salary \n",
    "and e1.employee_id <> e2.employee_id \n",
    "\n",
    "\n",
    "          \n",
    "                \"\"\")\n",
    "res8.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Departments Where No Employee Has a Salary Greater Than Their Manager's Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+-----------+------+----------+\n",
      "|employee_id|   name| department|salary|manager_id|\n",
      "+-----------+-------+-----------+------+----------+\n",
      "|          1|  Alice|Engineering| 80000|      null|\n",
      "|          2|    Bob|Engineering| 70000|         1|\n",
      "|          3|Charlie|Engineering| 60000|         1|\n",
      "|          4|  David|  Marketing| 90000|      null|\n",
      "|          5|    Eve|  Marketing| 55000|         4|\n",
      "|          6|  Frank|  Marketing| 65000|         4|\n",
      "|          7|  Grace|      Sales| 75000|      null|\n",
      "|          8| Hannah|      Sales| 70000|         7|\n",
      "|          9|    Ian|      Sales| 65000|         7|\n",
      "+-----------+-------+-----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------------+------------+\n",
      "|employee_id|employee_name|employee_salary|manager_name|\n",
      "+-----------+-------------+---------------+------------+\n",
      "+-----------+-------------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res9= spark.sql(\"\"\" \n",
    "select e.employee_id, e.name as employee_name, e.salary as employee_salary, m.name as manager_name\n",
    "FROM employee_table e\n",
    "inner join employee_table m\n",
    "on e.employee_id = m.manager_id \n",
    "and e.employee_id > m.employee_id \n",
    "\n",
    "\n",
    "          \n",
    "                \"\"\")\n",
    "res9.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Difference between employee salary and average Salary of department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+----------+----------+\n",
      "| department|   name|salary|avg_salary|difference|\n",
      "+-----------+-------+------+----------+----------+\n",
      "|Engineering|  Alice| 80000|   70000.0|   10000.0|\n",
      "|Engineering|    Bob| 70000|   70000.0|       0.0|\n",
      "|Engineering|Charlie| 60000|   70000.0|  -10000.0|\n",
      "|  Marketing|  David| 90000|   70000.0|   20000.0|\n",
      "|  Marketing|    Eve| 55000|   70000.0|  -15000.0|\n",
      "|  Marketing|  Frank| 65000|   70000.0|   -5000.0|\n",
      "|      Sales|  Grace| 75000|   70000.0|    5000.0|\n",
      "|      Sales| Hannah| 70000|   70000.0|       0.0|\n",
      "|      Sales|    Ian| 65000|   70000.0|   -5000.0|\n",
      "+-----------+-------+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res12 = spark.sql(\"\"\" \n",
    "SELECT e.department, e.name, e.salary, dept_avg.avg_salary, (e.salary - dept_avg.avg_salary) AS difference\n",
    "FROM employee_table e\n",
    "INNER JOIN (\n",
    "    SELECT department, AVG(salary) AS avg_salary\n",
    "    FROM employee_table\n",
    "    GROUP BY department\n",
    ") dept_avg\n",
    "ON e.department = dept_avg.department\n",
    "\"\"\")\n",
    "res12.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+-----------+-----------------+--------+\n",
      "|employee_id|salary| department|avg_sal_over_dept| diffsal|\n",
      "+-----------+------+-----------+-----------------+--------+\n",
      "|          1| 80000|Engineering|          70000.0| 10000.0|\n",
      "|          2| 70000|Engineering|          70000.0|     0.0|\n",
      "|          3| 60000|Engineering|          70000.0|-10000.0|\n",
      "|          4| 90000|  Marketing|          70000.0| 20000.0|\n",
      "|          5| 55000|  Marketing|          70000.0|-15000.0|\n",
      "|          6| 65000|  Marketing|          70000.0| -5000.0|\n",
      "|          7| 75000|      Sales|          70000.0|  5000.0|\n",
      "|          8| 70000|      Sales|          70000.0|     0.0|\n",
      "|          9| 65000|      Sales|          70000.0| -5000.0|\n",
      "+-----------+------+-----------+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res13 = spark.sql(\"\"\" \n",
    "SELECT employee_id,salary, department, \n",
    "avg(salary) over (partition by department) avg_sal_over_dept,\n",
    "salary - avg(salary) over (partition by department) as diffsal\n",
    "FROM employee_table \n",
    "\n",
    "\"\"\")\n",
    "res13.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employees whose salary is in top 2 percentile in department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|employee_id|salary|\n",
      "+-----------+------+\n",
      "|          3| 60000|\n",
      "|          5| 55000|\n",
      "|          9| 65000|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res15 = spark.sql(\"\"\" \n",
    "SELECT employee_id, salary \n",
    "FROM \n",
    "    (\n",
    "    SELECT employee_id, salary, department, \n",
    "           percent_rank() OVER (PARTITION BY department ORDER BY salary DESC) AS per_rnk \n",
    "    FROM employee_table\n",
    "    ) AS emp\n",
    "WHERE per_rnk >= 0.98\n",
    "\"\"\")\n",
    "res15.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employees who earn more than every employee in dept no sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|employee_id|salary|\n",
      "+-----------+------+\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res16 = spark.sql(\"\"\" \n",
    "SELECT employee_id, salary \n",
    "FROM employee_table\n",
    "WHERE salary > (SELECT MAX(salary) FROM employee_table WHERE department = 'sales')\n",
    "\"\"\")\n",
    "res16.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Department names ( with employee name) with more than 2 employee and salary greater than 90% of respective department averge salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+---------------+\n",
      "| department|dept_employee_count|dept_avg_salary|\n",
      "+-----------+-------------------+---------------+\n",
      "|Engineering|                  3|        70000.0|\n",
      "|  Marketing|                  3|        70000.0|\n",
      "|      Sales|                  3|        70000.0|\n",
      "+-----------+-------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res17 = spark.sql(\"\"\" \n",
    "SELECT department, \n",
    "       COUNT(name) AS dept_employee_count, \n",
    "       AVG(salary) AS dept_avg_salary\n",
    "FROM employee_table\n",
    "GROUP BY department \n",
    "HAVING dept_employee_count > 2 \n",
    "       AND dept_avg_salary > (0.90 * (SELECT AVG(salary) FROM employee_table WHERE department = department))\n",
    "ORDER BY dept_avg_salary\n",
    "\"\"\")\n",
    "res17.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "| department|\n",
      "+-----------+\n",
      "|Engineering|\n",
      "|      Sales|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res18 = spark.sql(\"\"\" \n",
    "SELECT DISTINCT department \n",
    "FROM (\n",
    "    SELECT employee_id, department,\n",
    "           SUM(CASE WHEN salary > 0.98 * avgsal THEN 1 ELSE 0 END) \n",
    "           OVER (PARTITION BY department) AS empCnt\n",
    "    FROM (\n",
    "        SELECT employee_id, department, salary, \n",
    "               AVG(salary) OVER (PARTITION BY department) AS avgsal \n",
    "        FROM employee_table\n",
    "    ) emp\n",
    ") emp1 \n",
    "WHERE empCnt >= 2\n",
    "\"\"\")\n",
    "res18.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select top 3 departments with at least 2 employees and rar    them accroding to the percentage fo their employees making over 100K in salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "| department|prcnt|\n",
      "+-----------+-----+\n",
      "|Engineering|  0.0|\n",
      "|  Marketing|  0.0|\n",
      "|      Sales|  0.0|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res19 = spark.sql(\"\"\" \n",
    "SELECT department,\n",
    "       100 * SUM(CASE WHEN salary >= 100000 THEN 1 ELSE 0 END) / COUNT(employee_id) AS prcnt\n",
    "FROM employee_table\n",
    "GROUP BY department\n",
    "HAVING COUNT(employee_id) > 2\n",
    "ORDER BY prcnt DESC\n",
    "LIMIT 3\n",
    "\"\"\")\n",
    "res19.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
